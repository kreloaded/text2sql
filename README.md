# Text2SQL

Convert natural language questions to SQL queries using AI-powered semantic search and code generation.

## ğŸš€ Features

- **Natural Language Processing**: Convert plain English questions to SQL queries
- **Semantic Search**: Uses FAISS vector store with sentence transformers for intelligent context retrieval
- **Spider Dataset**: Trained on 166 databases with 9,535+ examples
- **Side-by-Side View**: Modern UI showing question, SQL, schema, and similar examples
- **FastAPI Backend**: High-performance API with automatic documentation
- **Flask Frontend**: Clean, responsive web interface

## ğŸ“‹ Prerequisites

- Python 3.8 or higher
- Spider dataset (download from [Yale Spider](https://yale-lily.github.io/spider))
- 4GB+ RAM for FAISS index

## ğŸ› ï¸ Setup

### 1. Clone the Repository

```bash
git clone https://github.com/kreloaded/text2sql.git
cd text2sql
```

### 2. Download Spider Dataset

Download the Spider dataset and extract it:
```bash
# Download from https://yale-lily.github.io/spider
# Extract to your preferred location, e.g., ~/Downloads/spider_data
```

### 3. Setup Vector Service

```bash
cd backend/vector_service

# Create virtual environment
python3 -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Process Spider dataset
python preprocess_spider.py \
  --spider-dir /path/to/spider/data/directory \
  --database-dir /path/to/spider/data/directory/database

# Generate FAISS index (this may take 5-10 minutes)
python ingest.py --input output/spider_processed.json
```

### 4. Setup Backend

```bash
cd ../  # Move to backend directory

# Use the same virtual environment
source vector_service/venv/bin/activate

# Install backend dependencies (if not already installed)
pip install -r requirements.txt
```

### 5. Setup Frontend

```bash
cd ../frontend

# Create virtual environment for frontend
python3 -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

## ğŸ¯ Running the Application

You'll need to run both the backend and frontend servers.

### Terminal 1: Start Backend Server

```bash
cd backend
source vector_service/venv/bin/activate
PYTHONPATH=. python -m uvicorn main:app --host 0.0.0.0 --port 8000 --reload
```

Backend will be available at: http://localhost:8000
- API Documentation: http://localhost:8000/docs
- Health Check: http://localhost:8000/api/health

### Terminal 2: Start Frontend Server

```bash
cd frontend
source venv/bin/activate
python app.py
```

Frontend will be available at: http://localhost:5001

## ğŸ’¡ Usage

1. Open your browser and navigate to http://localhost:5001
2. Enter a natural language question (e.g., "How many singers do we have?")
3. Click "Generate SQL"
4. View the results in the side-by-side comparison:
   - **Left Panel**: Your question and generated SQL
   - **Right Panel**: Database schema and similar examples

## ğŸ“ Project Structure

```
text2sql/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ main.py                 # FastAPI application
â”‚   â”œâ”€â”€ config.py              # Configuration settings
â”‚   â”œâ”€â”€ requirements.txt       # Backend dependencies
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â””â”€â”€ schemas.py         # Pydantic models
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ retriever.py       # FAISS vector search
â”‚   â”‚   â””â”€â”€ sql_generator.py   # SQL generation logic
â”‚   â””â”€â”€ vector_service/
â”‚       â”œâ”€â”€ preprocess_spider.py  # Spider dataset processor
â”‚       â”œâ”€â”€ ingest.py            # FAISS index generator
â”‚       â””â”€â”€ output/              # Generated files
â”‚           â”œâ”€â”€ spider_processed.json
â”‚           â”œâ”€â”€ faiss.index
â”‚           â”œâ”€â”€ embeddings.npy
â”‚           â””â”€â”€ metadata.json
â””â”€â”€ frontend/
    â”œâ”€â”€ app.py                 # Flask application
    â”œâ”€â”€ requirements.txt       # Frontend dependencies
    â”œâ”€â”€ templates/
    â”‚   â””â”€â”€ index.html         # Main UI template
    â””â”€â”€ static/
        â”œâ”€â”€ css/
        â”‚   â””â”€â”€ style.css      # Styling
        â””â”€â”€ js/
            â””â”€â”€ main.js        # Frontend logic
```

## ğŸ”§ Configuration

### Backend Configuration (`backend/config.py`)

- `FAISS_INDEX_PATH`: Path to FAISS index file
- `METADATA_PATH`: Path to metadata JSON file
- `EMBEDDING_MODEL`: Sentence transformer model name
- `TOP_K`: Number of similar examples to retrieve

### Environment Variables

You can set these environment variables to override defaults:
```bash
export FAISS_INDEX_PATH=/custom/path/to/faiss.index
export METADATA_PATH=/custom/path/to/metadata.json
```

## ğŸ§ª Testing

### Test Backend API

```bash
cd backend
source vector_service/venv/bin/activate
python test_api.py
```

### Test Vector Service

```bash
cd backend
source vector_service/venv/bin/activate
python debug_payload.py
```

## ğŸ“Š Dataset Information

- **Databases**: 166 different database schemas
- **Total Entries**: 9,535 (876 schemas + 8,659 examples)
- **Source**: Spider dataset from Yale NLP
- **Format**: JSON with schema details, foreign keys, primary keys, and SQL examples

## ğŸ› Troubleshooting

### FAISS Index Not Found
```bash
# Regenerate the index
cd backend/vector_service
source venv/bin/activate
python ingest.py --input output/spider_processed.json
```

### Port Already in Use
```bash
# Backend (change port)
uvicorn main:app --port 8001

# Frontend (edit app.py to change port)
```

### Module Import Errors
```bash
# Make sure PYTHONPATH is set for backend
cd backend
PYTHONPATH=. python -m uvicorn main:app
```

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

## ğŸ“ License

This project is open source and available under the MIT License.

## ğŸ™ Acknowledgments

- **Spider Dataset**: Yale NLP Group
- **FAISS**: Facebook AI Research
- **Sentence Transformers**: UKPLab

## ğŸ“§ Contact

For questions or issues, please open an issue on GitHub.