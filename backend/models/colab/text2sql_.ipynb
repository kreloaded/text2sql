{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8XtvpZ0jM2JU"
      },
      "outputs": [],
      "source": [
        "# Install dependencies\n",
        "!pip install transformers torch flask pyngrok sentencepiece -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the model\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "import torch\n",
        "\n",
        "MODEL_NAME = \"tzaware/codet5p-spider-finetuned\"\n",
        "\n",
        "print(f\"Loading tokenizer and model from {MODEL_NAME}...\")\n",
        "try:\n",
        "    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "except:\n",
        "    print(\"Using fallback tokenizer\")\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\"Salesforce/codet5-base\")\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_NAME).to(device)\n",
        "model.eval()\n",
        "\n",
        "print(f\"âœ“ Model loaded on {device}\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "CUiCdKtVO3PH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Flask API\n",
        "from flask import Flask, request, jsonify\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "@app.route('/health', methods=['GET'])\n",
        "def health():\n",
        "    return jsonify({\"status\": \"healthy\", \"device\": device})\n",
        "\n",
        "@app.route('/generate', methods=['POST'])\n",
        "def generate():\n",
        "    try:\n",
        "        data = request.json\n",
        "        prompt = data.get('prompt', '')\n",
        "        max_new_tokens = data.get('max_new_tokens', 128)\n",
        "\n",
        "        # Tokenize\n",
        "        inputs = tokenizer(\n",
        "            prompt,\n",
        "            return_tensors=\"pt\",\n",
        "            max_length=512,\n",
        "            truncation=True,\n",
        "            padding=True\n",
        "        ).to(device)\n",
        "\n",
        "        # Generate\n",
        "        with torch.no_grad():\n",
        "            outputs = model.generate(\n",
        "                input_ids=inputs['input_ids'],\n",
        "                attention_mask=inputs.get('attention_mask', None),\n",
        "                max_new_tokens=max_new_tokens,\n",
        "                num_beams=4,\n",
        "                early_stopping=True,\n",
        "                pad_token_id=tokenizer.pad_token_id or tokenizer.eos_token_id,\n",
        "                eos_token_id=tokenizer.eos_token_id\n",
        "            )\n",
        "\n",
        "        # Decode\n",
        "        sql_query = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "        return jsonify({\n",
        "            \"generated_sql\": sql_query.strip(),\n",
        "            \"status\": \"success\"\n",
        "        })\n",
        "\n",
        "    except Exception as e:\n",
        "        return jsonify({\n",
        "            \"error\": str(e),\n",
        "            \"status\": \"error\"\n",
        "        }), 500\n",
        "\n",
        "print(\"âœ“ Flask API created\")"
      ],
      "metadata": {
        "id": "hv5qqOy3Ph75"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup ngrok\n",
        "from pyngrok import ngrok\n",
        "import getpass\n",
        "\n",
        "# Get ngrok auth token\n",
        "print(\"Get your ngrok auth token from: https://dashboard.ngrok.com/get-started/your-authtoken\")\n",
        "ngrok_token = getpass.getpass(\"Enter your ngrok auth token: \")\n",
        "ngrok.set_auth_token(ngrok_token)\n",
        "\n",
        "# Start ngrok tunnel\n",
        "public_url = ngrok.connect(5000)\n",
        "print(f\"\\n\" + \"=\"*60)\n",
        "print(f\"ðŸš€ Model Server Running!\")\n",
        "print(f\"Public URL: {public_url}\")\n",
        "print(f\"=\"*60)\n",
        "print(f\"\\nUse this URL in your backend config:\")\n",
        "print(f\"CUSTOM_MODEL_API_URL = '{public_url}'\")\n",
        "print(f\"\\nTest it: curl {public_url}/health\")"
      ],
      "metadata": {
        "id": "T2g5JxywPq8-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the Flask server\n",
        "from flask import Flask\n",
        "import threading\n",
        "\n",
        "def run_app():\n",
        "    app.run(port=5000, debug=False, use_reloader=False)\n",
        "\n",
        "# Start server in background thread\n",
        "server_thread = threading.Thread(target=run_app, daemon=True)\n",
        "server_thread.start()\n",
        "\n",
        "print(\"\\nâœ“ Server is running! Keep this cell running...\")\n",
        "print(\"Press Ctrl+C to stop the server\")\n",
        "\n",
        "# Keep the cell running\n",
        "import time\n",
        "try:\n",
        "    while True:\n",
        "        time.sleep(1)\n",
        "except KeyboardInterrupt:\n",
        "    print(\"\\nServer stopped\")"
      ],
      "metadata": {
        "id": "SMOBvS9_QlJ_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}